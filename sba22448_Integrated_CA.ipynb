{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "295b67e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import tarfile\n",
    "import json\n",
    "import bz2\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15f786fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import udf, desc, min, max, to_timestamp, to_date, date_format, col, expr, hour, year, month, dayofweek, count\n",
    "from pyspark.sql import functions as F #module that includes a variety of functions like to extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10085277",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://cacu-VirtualBox.mshome.net:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=PySparkShell>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f84622aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599995</th>\n",
       "      <td>1599995</td>\n",
       "      <td>2193601966</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>AmandaMarie1028</td>\n",
       "      <td>Just woke up. Having no school is the best fee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599996</th>\n",
       "      <td>1599996</td>\n",
       "      <td>2193601969</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>TheWDBoards</td>\n",
       "      <td>TheWDB.com - Very cool to hear old Walt interv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599997</th>\n",
       "      <td>1599997</td>\n",
       "      <td>2193601991</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>bpbabe</td>\n",
       "      <td>Are you ready for your MoJo Makeover? Ask me f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599998</th>\n",
       "      <td>1599998</td>\n",
       "      <td>2193602064</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>tinydiamondz</td>\n",
       "      <td>Happy 38th Birthday to my boo of alll time!!! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599999</th>\n",
       "      <td>1599999</td>\n",
       "      <td>2193602129</td>\n",
       "      <td>Tue Jun 16 08:40:50 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>RyanTrevMorris</td>\n",
       "      <td>happy #charitytuesday @theNSPCC @SparksCharity...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600000 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           index          id                          date      flag  \\\n",
       "0              0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1              1  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2              2  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3              3  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4              4  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "...          ...         ...                           ...       ...   \n",
       "1599995  1599995  2193601966  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599996  1599996  2193601969  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599997  1599997  2193601991  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599998  1599998  2193602064  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599999  1599999  2193602129  Tue Jun 16 08:40:50 PDT 2009  NO_QUERY   \n",
       "\n",
       "                    user                                               text  \n",
       "0        _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1          scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "2               mattycus  @Kenichan I dived many times for the ball. Man...  \n",
       "3                ElleCTF    my whole body feels itchy and like its on fire   \n",
       "4                 Karoli  @nationwideclass no, it's not behaving at all....  \n",
       "...                  ...                                                ...  \n",
       "1599995  AmandaMarie1028  Just woke up. Having no school is the best fee...  \n",
       "1599996      TheWDBoards  TheWDB.com - Very cool to hear old Walt interv...  \n",
       "1599997           bpbabe  Are you ready for your MoJo Makeover? Ask me f...  \n",
       "1599998     tinydiamondz  Happy 38th Birthday to my boo of alll time!!! ...  \n",
       "1599999   RyanTrevMorris  happy #charitytuesday @theNSPCC @SparksCharity...  \n",
       "\n",
       "[1600000 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#viewing dataset as pd df\n",
    "columns = [\"index\", \"id\", \"date\", \"flag\", \"user\", \"text\"]\n",
    "pdDf = pd.read_csv(\"ProjectTweets.csv\", header=None, names=columns)\n",
    "\n",
    "pdDf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859bdee5",
   "metadata": {},
   "source": [
    "### Loading csv data file to spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d699ac41",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- index: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- date: timestamp (nullable = true)\n",
      " |-- flag: string (nullable = true)\n",
      " |-- user: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-------------------+--------+---------------+--------------------+\n",
      "|index|        id|               date|    flag|           user|                text|\n",
      "+-----+----------+-------------------+--------+---------------+--------------------+\n",
      "|    0|1467810369|2009-04-07 06:19:45|NO_QUERY|_TheSpecialOne_|@switchfoot http:...|\n",
      "|    1|1467810672|2009-04-07 06:19:49|NO_QUERY|  scotthamilton|is upset that he ...|\n",
      "|    2|1467810917|2009-04-07 06:19:53|NO_QUERY|       mattycus|@Kenichan I dived...|\n",
      "|    3|1467811184|2009-04-07 06:19:57|NO_QUERY|        ElleCTF|my whole body fee...|\n",
      "|    4|1467811193|2009-04-07 06:19:57|NO_QUERY|         Karoli|@nationwideclass ...|\n",
      "|    5|1467811372|2009-04-07 06:20:00|NO_QUERY|       joy_wolf|@Kwesidei not the...|\n",
      "|    6|1467811592|2009-04-07 06:20:03|NO_QUERY|        mybirch|         Need a hug |\n",
      "|    7|1467811594|2009-04-07 06:20:03|NO_QUERY|           coZZ|@LOLTrish hey  lo...|\n",
      "|    8|1467811795|2009-04-07 06:20:05|NO_QUERY|2Hood4Hollywood|@Tatiana_K nope t...|\n",
      "|    9|1467812025|2009-04-07 06:20:09|NO_QUERY|        mimismo|@twittera que me ...|\n",
      "|   10|1467812416|2009-04-07 06:20:16|NO_QUERY| erinx3leannexo|spring break in p...|\n",
      "|   11|1467812579|2009-04-07 06:20:17|NO_QUERY|   pardonlauren|I just re-pierced...|\n",
      "|   12|1467812723|2009-04-07 06:20:19|NO_QUERY|           TLeC|@caregiving I cou...|\n",
      "|   13|1467812771|2009-04-07 06:20:19|NO_QUERY|robrobbierobert|@octolinz16 It it...|\n",
      "|   14|1467812784|2009-04-07 06:20:20|NO_QUERY|    bayofwolves|@smarrison i woul...|\n",
      "|   15|1467812799|2009-04-07 06:20:20|NO_QUERY|     HairByJess|@iamjazzyfizzle I...|\n",
      "|   16|1467812964|2009-04-07 06:20:22|NO_QUERY| lovesongwriter|Hollis' death sce...|\n",
      "|   17|1467813137|2009-04-07 06:20:25|NO_QUERY|       armotley|about to file taxes |\n",
      "|   18|1467813579|2009-04-07 06:20:31|NO_QUERY|     starkissed|@LettyA ahh ive a...|\n",
      "|   19|1467813782|2009-04-07 06:20:34|NO_QUERY|      gi_gi_bee|@FakerPattyPattz ...|\n",
      "+-----+----------+-------------------+--------+---------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Issue with pattern in the DateTimeFormatter when converting to timestamp due to spark version. Setting timeParserPolicy to LEGACY as the error suggested\n",
    "spark.conf.set(\"spark.sql.legacy.timeParserPolicy\",\"LEGACY\") \n",
    "\n",
    "#defining schema\n",
    "schema = StructType([\n",
    "    StructField(\"index\", StringType(), True),\n",
    "    StructField(\"id\", StringType(), True),\n",
    "    StructField(\"date\", StringType(), True),\n",
    "    StructField(\"flag\", StringType(), True),\n",
    "    StructField(\"user\", StringType(), True),\n",
    "    StructField(\"text\", StringType(), True),\n",
    "])\n",
    "\n",
    "tweetsDf= spark.read.csv('hdfs://localhost:9000/user1/ProjectTweets.csv', schema=schema, header=False)\n",
    "\n",
    "# converting date column to timestamp, pattern taken from https://spark.apache.org/docs/latest/sql-ref-datetime-pattern.html\n",
    "tweetsDf= tweetsDf.withColumn(\"date\", to_timestamp(\"date\", \"EEE MMM dd HH:mm:ss zzz yyyy\"))\n",
    "\n",
    "tweetsDf.printSchema();tweetsDf.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239a0397",
   "metadata": {},
   "source": [
    "checking flag column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ff348e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(flag='NO_QUERY')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extracting \"flag\" column as RDD\n",
    "flag_rdd = tweetsDf.select(\"flag\").rdd\n",
    "\n",
    "# getting distinct values\n",
    "unique_flags = flag_rdd.distinct()\n",
    "\n",
    "#collecting the distinct values\n",
    "unique_flags.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e228bc52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1685"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# counting the number of duplicated IDs\n",
    "tweetsDf.groupBy(\"id\").count().filter(col(\"count\") > 1).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1320c71d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1685"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#counting the number of duplicated rows, leaving index aside\n",
    "tweetsDf.groupBy([\"id\", \"date\", \"flag\", \"user\", \"text\"]).count().filter(col(\"count\") > 1).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f71440e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1600000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#number of rows\n",
    "tweetsDf.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ba4c94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping rows with duplicate IDs (keeping the first occurrence)\n",
    "tweetsDf= tweetsDf.dropDuplicates([\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b784ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1598315"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#number of rows\n",
    "tweetsDf.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47134bbc",
   "metadata": {},
   "source": [
    "Checking users with greatest count of tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9da12a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 26:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----+\n",
      "|           user|count|\n",
      "+---------------+-----+\n",
      "|       lost_dog|  549|\n",
      "|        webwoke|  345|\n",
      "|       tweetpet|  310|\n",
      "|SallytheShizzle|  281|\n",
      "|    VioletsCRUK|  279|\n",
      "|    mcraddictal|  276|\n",
      "|       tsarnick|  248|\n",
      "|    what_bugs_u|  246|\n",
      "|    Karen230683|  238|\n",
      "|      DarkPiano|  236|\n",
      "|   SongoftheOss|  227|\n",
      "|      Jayme1988|  225|\n",
      "|         keza34|  219|\n",
      "| ramdomthoughts|  216|\n",
      "|      shanajaca|  213|\n",
      "|         wowlew|  212|\n",
      "|     nuttychris|  211|\n",
      "|   TraceyHewins|  211|\n",
      "|   thisgoeshere|  207|\n",
      "|     Spidersamm|  205|\n",
      "+---------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# registerring the df as a temporary view\n",
    "tweetsDf.createOrReplaceTempView(\"tweets\")\n",
    "\n",
    "# SQL query\n",
    "query = \"\"\"SELECT user, COUNT(*) as count\n",
    "    FROM tweets\n",
    "    GROUP BY user\n",
    "    ORDER BY count DESC\"\"\"\n",
    "\n",
    "# running the SQL query and showing result\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453d8738",
   "metadata": {},
   "source": [
    "### DATES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "227deb9e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 32:======================================>                   (2 + 1) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-------------------+--------+---------------+--------------------+\n",
      "|index|        id|               date|    flag|           user|                text|\n",
      "+-----+----------+-------------------+--------+---------------+--------------------+\n",
      "|    0|1467810369|2009-04-07 06:19:45|NO_QUERY|_TheSpecialOne_|@switchfoot http:...|\n",
      "|    1|1467810672|2009-04-07 06:19:49|NO_QUERY|  scotthamilton|is upset that he ...|\n",
      "|    2|1467810917|2009-04-07 06:19:53|NO_QUERY|       mattycus|@Kenichan I dived...|\n",
      "|    4|1467811193|2009-04-07 06:19:57|NO_QUERY|         Karoli|@nationwideclass ...|\n",
      "|    3|1467811184|2009-04-07 06:19:57|NO_QUERY|        ElleCTF|my whole body fee...|\n",
      "|    5|1467811372|2009-04-07 06:20:00|NO_QUERY|       joy_wolf|@Kwesidei not the...|\n",
      "|    6|1467811592|2009-04-07 06:20:03|NO_QUERY|        mybirch|         Need a hug |\n",
      "|    7|1467811594|2009-04-07 06:20:03|NO_QUERY|           coZZ|@LOLTrish hey  lo...|\n",
      "|    8|1467811795|2009-04-07 06:20:05|NO_QUERY|2Hood4Hollywood|@Tatiana_K nope t...|\n",
      "|    9|1467812025|2009-04-07 06:20:09|NO_QUERY|        mimismo|@twittera que me ...|\n",
      "|   10|1467812416|2009-04-07 06:20:16|NO_QUERY| erinx3leannexo|spring break in p...|\n",
      "|   11|1467812579|2009-04-07 06:20:17|NO_QUERY|   pardonlauren|I just re-pierced...|\n",
      "|   12|1467812723|2009-04-07 06:20:19|NO_QUERY|           TLeC|@caregiving I cou...|\n",
      "|   13|1467812771|2009-04-07 06:20:19|NO_QUERY|robrobbierobert|@octolinz16 It it...|\n",
      "|   14|1467812784|2009-04-07 06:20:20|NO_QUERY|    bayofwolves|@smarrison i woul...|\n",
      "|   15|1467812799|2009-04-07 06:20:20|NO_QUERY|     HairByJess|@iamjazzyfizzle I...|\n",
      "|   16|1467812964|2009-04-07 06:20:22|NO_QUERY| lovesongwriter|Hollis' death sce...|\n",
      "|   17|1467813137|2009-04-07 06:20:25|NO_QUERY|       armotley|about to file taxes |\n",
      "|   18|1467813579|2009-04-07 06:20:31|NO_QUERY|     starkissed|@LettyA ahh ive a...|\n",
      "|   19|1467813782|2009-04-07 06:20:34|NO_QUERY|      gi_gi_bee|@FakerPattyPattz ...|\n",
      "+-----+----------+-------------------+--------+---------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Ordering rows by date\n",
    "tweetsDf= tweetsDf.orderBy(\"date\")\n",
    "tweetsDf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62e0857c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking if the df is ordered by id\n",
    "tweetsDf.agg(F.min(\"id\").alias(\"min_id\"), F.max(\"id\").alias(\"max_id\")) \\ # aggregation on the df and calculation of the min and max values of parameter \"id\" \n",
    "                    .select(F.col(\"min_id\") < F.col(\"max_id\")) \\ #checking if min_id < max_id, returning a df with a single Boolean value\n",
    "                    .collect()[0][0] # collect executes the transformations and select access row 0 column 0 from resulting df\n",
    "\n",
    "# True confirms the df is ordered by id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "34a6ea5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# is the df ordered by index? Same code as above\n",
    "tweetsDf.agg(F.min(\"index\").alias(\"min_index\"), F.max(\"index\").alias(\"max_index\")) \\\n",
    "                    .select(F.col(\"min_index\") < F.col(\"max_index\")) \\\n",
    "                    .collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9d73d519",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "window should be WindowSpec",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_16499/453139443.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Add a column that represents the previous 'date' value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtweetsDf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtweetsDf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"prev_date\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"date\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mover\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweetsDf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Filter out rows where there is a missing date\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/column.py\u001b[0m in \u001b[0;36mover\u001b[0;34m(self, window)\u001b[0m\n\u001b[1;32m    900\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWindowSpec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWindowSpec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 902\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"window should be WindowSpec\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    903\u001b[0m         \u001b[0mjc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mover\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jspec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: window should be WindowSpec"
     ]
    }
   ],
   "source": [
    "# from pyspark.sql.window import Window\n",
    "\n",
    "# # Create a window specification to define the order by 'date'\n",
    "# windowSpec = Window.orderBy(\"date\")\n",
    "\n",
    "# Add a column that represents the previous 'date' value\n",
    "tweetsDf = tweetsDf.withColumn(\"prev_date\", F.lag(\"date\").over(tweetsDf))\n",
    "\n",
    "# Filter out rows where there is a missing date\n",
    "missing_dates_df = tweetsDf.filter((F.col(\"date\") - F.col(\"prev_date\") > F.expr(\"INTERVAL 1 DAY\")) | F.col(\"prev_date\").isNull())\n",
    "\n",
    "# Show the rows before the missing date\n",
    "missing_dates_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e701834",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweetsDf.agg(F.min(\"date\")).collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a9c277",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweetsDf.agg(F.max(\"date\")).collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "705e6147",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-27 03:26:17,852 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "2023-07-27 03:26:17,856 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "2023-07-27 03:26:26,609 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "2023-07-27 03:26:30,579 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "[Stage 86:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+-------------------+--------+---------------+--------------------+-----------+\n",
      "|  index|        id|               date|    flag|           user|                text|gap_seconds|\n",
      "+-------+----------+-------------------+--------+---------------+--------------------+-----------+\n",
      "|      0|1467810369|2009-04-07 06:19:45|NO_QUERY|_TheSpecialOne_|@switchfoot http:...| 1239081585|\n",
      "|  41607|1675708196|2009-05-02 04:08:46|NO_QUERY|        jayseto|jayseto@KevinSpac...|     920791|\n",
      "|   8575|1548274671|2009-04-18 04:30:31|NO_QUERY|   xoLovebug224|Working on my son...|     906261|\n",
      "| 460800|2169448960|2009-06-14 22:31:20|NO_QUERY|        ddrfire|@squarespace Dang...|     580723|\n",
      "|  77476|1750882626|2009-05-10 02:08:48|NO_QUERY|     m3l0v3sr0n|2 more hours of w...|     469053|\n",
      "| 135509|1879906505|2009-05-22 07:29:41|NO_QUERY|    antcastillo|@terencefitz yeah...|     314081|\n",
      "| 104024|1822312820|2009-05-17 03:17:07|NO_QUERY|ReLLySiLLyViLLy|My feet hurt soo ...|     205379|\n",
      "|  94940|1791596898|2009-05-14 04:34:10|NO_QUERY|TransitionalTee|My Twitter stream...|     161702|\n",
      "| 150318|1914415450|2009-05-25 18:42:48|NO_QUERY|missmichiganusa|I'm soooo hungry!...|     146174|\n",
      "| 155113|1955759808|2009-05-29 04:34:52|NO_QUERY|      AshIngram|I love dead phone...|     133634|\n",
      "| 150389|1932263977|2009-05-27 05:07:53|NO_QUERY|   loveandbooze|Thanks to @grapej...|     123811|\n",
      "| 150244|1898392818|2009-05-24 02:04:32|NO_QUERY|Rachel_Lauren24|Everyone is havin...|     119378|\n",
      "| 744996|2282094971|2009-06-22 18:56:11|NO_QUERY|    McflyBabe09|I NEED TO KNOW WH...|      89906|\n",
      "|  93175|1770537730|2009-05-12 05:36:45|NO_QUERY|   stunned_beef|@jladan Aww. That...|      87415|\n",
      "| 774008|2321353373|2009-06-25 04:56:18|NO_QUERY|    sarahmollus|@Trentopolis that...|      79223|\n",
      "|1340294|2030210665|2009-06-04 16:02:36|NO_QUERY|     Snailified|HMMMMM. If i can'...|      75888|\n",
      "|  37028|1572830720|2009-04-21 06:42:46|NO_QUERY|    Vickboogiii|@CrysAnGeL77 ..th...|      52943|\n",
      "| 757005|2295170615|2009-06-23 15:34:38|NO_QUERY|       BunnySan|i wake up every m...|      38911|\n",
      "| 355320|2043889162|2009-06-05 16:33:46|NO_QUERY|      Karim1980|Tummy ache on a F...|      33134|\n",
      "| 354119|2039642945|2009-06-05 06:27:10|NO_QUERY|         Celin3|@pcdnicole Nicole...|      32562|\n",
      "+-------+----------+-------------------+--------+---------------+--------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sql_query = \"\"\"\n",
    "SELECT *,\n",
    "       UNIX_TIMESTAMP(date) - LAG(UNIX_TIMESTAMP(date), 1, 0) OVER (ORDER BY date) AS gap_seconds\n",
    "FROM tweets\n",
    "ORDER BY gap_seconds DESC\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(sql_query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71de927b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gaps_df = spark.sql(\"\"\"\n",
    "    SELECT DATE_ADD(d1, 1) AS missing_date\n",
    "    FROM (\n",
    "        SELECT CAST(date AS DATE) AS d1, \n",
    "               LEAD(CAST(date AS DATE), 1) OVER (ORDER BY date) AS d2\n",
    "        FROM tweets\n",
    "    ) temp\n",
    "    WHERE DATE_ADD(d1, 1) < d2\n",
    "\"\"\")\n",
    "\n",
    "# Count the number of gaps in days\n",
    "gaps_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3c109cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-27 03:27:16,272 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "2023-07-27 03:27:16,276 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "2023-07-27 03:27:24,623 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "2023-07-27 03:27:28,127 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "[Stage 92:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+-------------------+--------+-------------+-------------------------------------------------------------------------------------------------------------------------------+----------+----------+\n",
      "|index  |id        |date               |flag    |user         |text                                                                                                                           |next_date |lead_date |\n",
      "+-------+----------+-------------------+--------+-------------+-------------------------------------------------------------------------------------------------------------------------------+----------+----------+\n",
      "|812095 |1470241255|2009-04-07 16:46:10|NO_QUERY|tallcathy    |That's why I love ya jimmy                                                                                                     |2009-04-08|2009-04-18|\n",
      "|858416 |1574131184|2009-04-21 12:22:15|NO_QUERY|LaDy_aLySsa  |@KattPackAllDay THIS SHIT RIGHT HEREEEEEEEEE                                                                                   |2009-04-22|2009-05-02|\n",
      "|908512 |1696219758|2009-05-04 15:51:15|NO_QUERY|Gemmaboyle   |@mariannemarlow It is a drink but they have a trainer brand too.. http://www.office.co.uk/brand/babycham/8 &lt;&lt;have a look |2009-05-05|2009-05-10|\n",
      "|94938  |1771236595|2009-05-12 07:39:08|NO_QUERY|niknak70     |has a poorly little boy                                                                                                        |2009-05-13|2009-05-14|\n",
      "|945442 |1796906169|2009-05-14 18:14:08|NO_QUERY|franalations |@StevenGonzaleS I got drunk with my friends                                                                                    |2009-05-15|2009-05-17|\n",
      "|135508 |1836581116|2009-05-18 16:15:00|NO_QUERY|rehna_tu     |@dharshana My earphone has bid my goodbye!  I kept it sooo safely...and yet!!!                                                 |2009-05-19|2009-05-22|\n",
      "|1026199|1883664966|2009-05-22 16:54:54|NO_QUERY|calabash11   |@JustinNXT Shapoww.  #yachtrockfriday ? http://blip.fm/~6tjlw                                                                  |2009-05-23|2009-05-24|\n",
      "|1026392|1914430285|2009-05-25 18:44:22|NO_QUERY|poppymom     |@TwentyCarlo I don't feel so bad about eating Everything crackers dipped in blue cheese dressing now!                          |2009-05-26|2009-05-27|\n",
      "|1033287|1936103148|2009-05-27 15:27:38|NO_QUERY|svenringling |Recently published book on HR-IT keeps bringing subscribers to our free strategic HCM newsletter   http://bit.ly/lVOP7         |2009-05-28|2009-05-29|\n",
      "|1506279|2072531898|2009-06-08 05:12:37|NO_QUERY|stellargellar|Currently Browsing:undefined http://is.gd/SuFs amazing.                                                                        |2009-06-09|2009-06-14|\n",
      "+-------+----------+-------------------+--------+-------------+-------------------------------------------------------------------------------------------------------------------------------+----------+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Use SQL with a CTE to find the rows with missing timestamps in between\n",
    "result_df = spark.sql(\"\"\"\n",
    "    WITH Temp AS (\n",
    "        SELECT *,\n",
    "               DATE_ADD(CAST(date AS DATE), 1) AS next_date,\n",
    "               LEAD(CAST(date AS DATE), 1) OVER (ORDER BY date) AS lead_date\n",
    "        FROM tweets\n",
    "    )\n",
    "    SELECT *\n",
    "    FROM Temp\n",
    "    WHERE next_date < lead_date\n",
    "\"\"\")\n",
    "\n",
    "# Show the resulting DataFrame with rows that have missing timestamps in between\n",
    "result_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc4bd54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
