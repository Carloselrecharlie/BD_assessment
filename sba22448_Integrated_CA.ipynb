{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "295b67e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import tarfile\n",
    "import json\n",
    "import bz2\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15f786fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import udf, desc, min, max, to_timestamp, to_date, date_format, col, expr, hour, year, month, dayofweek, count\n",
    "from pyspark.sql import functions as F #module that includes a variety of functions like to extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10085277",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://cacu-VirtualBox.mshome.net:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=PySparkShell>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f84622aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599995</th>\n",
       "      <td>1599995</td>\n",
       "      <td>2193601966</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>AmandaMarie1028</td>\n",
       "      <td>Just woke up. Having no school is the best fee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599996</th>\n",
       "      <td>1599996</td>\n",
       "      <td>2193601969</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>TheWDBoards</td>\n",
       "      <td>TheWDB.com - Very cool to hear old Walt interv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599997</th>\n",
       "      <td>1599997</td>\n",
       "      <td>2193601991</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>bpbabe</td>\n",
       "      <td>Are you ready for your MoJo Makeover? Ask me f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599998</th>\n",
       "      <td>1599998</td>\n",
       "      <td>2193602064</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>tinydiamondz</td>\n",
       "      <td>Happy 38th Birthday to my boo of alll time!!! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599999</th>\n",
       "      <td>1599999</td>\n",
       "      <td>2193602129</td>\n",
       "      <td>Tue Jun 16 08:40:50 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>RyanTrevMorris</td>\n",
       "      <td>happy #charitytuesday @theNSPCC @SparksCharity...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600000 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           index          id                          date      flag  \\\n",
       "0              0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1              1  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2              2  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3              3  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4              4  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "...          ...         ...                           ...       ...   \n",
       "1599995  1599995  2193601966  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599996  1599996  2193601969  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599997  1599997  2193601991  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599998  1599998  2193602064  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599999  1599999  2193602129  Tue Jun 16 08:40:50 PDT 2009  NO_QUERY   \n",
       "\n",
       "                    user                                               text  \n",
       "0        _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1          scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "2               mattycus  @Kenichan I dived many times for the ball. Man...  \n",
       "3                ElleCTF    my whole body feels itchy and like its on fire   \n",
       "4                 Karoli  @nationwideclass no, it's not behaving at all....  \n",
       "...                  ...                                                ...  \n",
       "1599995  AmandaMarie1028  Just woke up. Having no school is the best fee...  \n",
       "1599996      TheWDBoards  TheWDB.com - Very cool to hear old Walt interv...  \n",
       "1599997           bpbabe  Are you ready for your MoJo Makeover? Ask me f...  \n",
       "1599998     tinydiamondz  Happy 38th Birthday to my boo of alll time!!! ...  \n",
       "1599999   RyanTrevMorris  happy #charitytuesday @theNSPCC @SparksCharity...  \n",
       "\n",
       "[1600000 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#viewing dataset as pd df\n",
    "columns = [\"index\", \"id\", \"date\", \"flag\", \"user\", \"text\"]\n",
    "pdDf = pd.read_csv(\"ProjectTweets.csv\", header=None, names=columns)\n",
    "\n",
    "pdDf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859bdee5",
   "metadata": {},
   "source": [
    "### Loading csv data file to spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d699ac41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- index: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- date: timestamp (nullable = true)\n",
      " |-- flag: string (nullable = true)\n",
      " |-- user: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-------------------+--------+---------------+--------------------+\n",
      "|index|        id|               date|    flag|           user|                text|\n",
      "+-----+----------+-------------------+--------+---------------+--------------------+\n",
      "|    0|1467810369|2009-04-07 06:19:45|NO_QUERY|_TheSpecialOne_|@switchfoot http:...|\n",
      "|    1|1467810672|2009-04-07 06:19:49|NO_QUERY|  scotthamilton|is upset that he ...|\n",
      "|    2|1467810917|2009-04-07 06:19:53|NO_QUERY|       mattycus|@Kenichan I dived...|\n",
      "|    3|1467811184|2009-04-07 06:19:57|NO_QUERY|        ElleCTF|my whole body fee...|\n",
      "|    4|1467811193|2009-04-07 06:19:57|NO_QUERY|         Karoli|@nationwideclass ...|\n",
      "|    5|1467811372|2009-04-07 06:20:00|NO_QUERY|       joy_wolf|@Kwesidei not the...|\n",
      "|    6|1467811592|2009-04-07 06:20:03|NO_QUERY|        mybirch|         Need a hug |\n",
      "|    7|1467811594|2009-04-07 06:20:03|NO_QUERY|           coZZ|@LOLTrish hey  lo...|\n",
      "|    8|1467811795|2009-04-07 06:20:05|NO_QUERY|2Hood4Hollywood|@Tatiana_K nope t...|\n",
      "|    9|1467812025|2009-04-07 06:20:09|NO_QUERY|        mimismo|@twittera que me ...|\n",
      "|   10|1467812416|2009-04-07 06:20:16|NO_QUERY| erinx3leannexo|spring break in p...|\n",
      "|   11|1467812579|2009-04-07 06:20:17|NO_QUERY|   pardonlauren|I just re-pierced...|\n",
      "|   12|1467812723|2009-04-07 06:20:19|NO_QUERY|           TLeC|@caregiving I cou...|\n",
      "|   13|1467812771|2009-04-07 06:20:19|NO_QUERY|robrobbierobert|@octolinz16 It it...|\n",
      "|   14|1467812784|2009-04-07 06:20:20|NO_QUERY|    bayofwolves|@smarrison i woul...|\n",
      "|   15|1467812799|2009-04-07 06:20:20|NO_QUERY|     HairByJess|@iamjazzyfizzle I...|\n",
      "|   16|1467812964|2009-04-07 06:20:22|NO_QUERY| lovesongwriter|Hollis' death sce...|\n",
      "|   17|1467813137|2009-04-07 06:20:25|NO_QUERY|       armotley|about to file taxes |\n",
      "|   18|1467813579|2009-04-07 06:20:31|NO_QUERY|     starkissed|@LettyA ahh ive a...|\n",
      "|   19|1467813782|2009-04-07 06:20:34|NO_QUERY|      gi_gi_bee|@FakerPattyPattz ...|\n",
      "+-----+----------+-------------------+--------+---------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Issue with pattern in the DateTimeFormatter when converting to timestamp due to spark version. Setting timeParserPolicy to LEGACY as the error suggested\n",
    "spark.conf.set(\"spark.sql.legacy.timeParserPolicy\",\"LEGACY\") \n",
    "\n",
    "#defining schema\n",
    "schema = StructType([\n",
    "    StructField(\"index\", StringType(), True),\n",
    "    StructField(\"id\", StringType(), True),\n",
    "    StructField(\"date\", StringType(), True),\n",
    "    StructField(\"flag\", StringType(), True),\n",
    "    StructField(\"user\", StringType(), True),\n",
    "    StructField(\"text\", StringType(), True)\n",
    "])\n",
    "\n",
    "tweetsDf= spark.read.csv('hdfs://localhost:9000/user1/ProjectTweets.csv', schema=schema, header=False)\n",
    "\n",
    "# converting date column to timestamp, pattern taken from https://spark.apache.org/docs/latest/sql-ref-datetime-pattern.html\n",
    "tweetsDf= tweetsDf.withColumn(\"date\", to_timestamp(\"date\", \"EEE MMM dd HH:mm:ss zzz yyyy\"))\n",
    "\n",
    "tweetsDf.printSchema();tweetsDf.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239a0397",
   "metadata": {},
   "source": [
    "checking flag column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ff348e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(flag='NO_QUERY')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extracting \"flag\" column as RDD, showing unique values with distinct funcion and showing with collect()\n",
    "tweetsDf.select(\"flag\").rdd.distinct().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e228bc52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1685"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# counting the number of duplicated IDs, grouping by id and filterring out rows where id count is 1. Then counting those rows\n",
    "tweetsDf.groupBy(\"id\").count().filter(col(\"count\") > 1).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1320c71d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1685"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#counting the number of duplicated rows, same as above but addind the remaining features except index because this one would always be different\n",
    "tweetsDf.groupBy([\"id\", \"date\", \"flag\", \"user\", \"text\"]).count().filter(col(\"count\") > 1).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f71440e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1600000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#number of rows\n",
    "tweetsDf.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ba4c94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping rows with duplicate IDs (keeping the first occurrence)\n",
    "tweetsDf= tweetsDf.dropDuplicates([\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b784ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1598315"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#number of rows\n",
    "tweetsDf.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47134bbc",
   "metadata": {},
   "source": [
    "Checking number of unique users and users with greatest count of tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e1514df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "659775"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of unique users as RDD, same as done with attribute 'flag'\n",
    "tweetsDf.select(\"user\").rdd.distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9da12a51",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----+\n",
      "|           user|count|\n",
      "+---------------+-----+\n",
      "|       lost_dog|  549|\n",
      "|        webwoke|  345|\n",
      "|       tweetpet|  310|\n",
      "|SallytheShizzle|  281|\n",
      "|    VioletsCRUK|  279|\n",
      "|    mcraddictal|  276|\n",
      "|       tsarnick|  248|\n",
      "|    what_bugs_u|  246|\n",
      "|    Karen230683|  238|\n",
      "|      DarkPiano|  236|\n",
      "|   SongoftheOss|  227|\n",
      "|      Jayme1988|  225|\n",
      "|         keza34|  219|\n",
      "| ramdomthoughts|  216|\n",
      "|      shanajaca|  213|\n",
      "|         wowlew|  212|\n",
      "|     nuttychris|  211|\n",
      "|   TraceyHewins|  211|\n",
      "|   thisgoeshere|  207|\n",
      "|     Spidersamm|  205|\n",
      "+---------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#users with greatest count of tweets\n",
    "# registerring the df as a temporary view\n",
    "tweetsDf.createOrReplaceTempView(\"tweets\")\n",
    "\n",
    "# SQL query, selecting user column and adding another column called count showing the counts in descendent order\n",
    "query = \"\"\"SELECT user, COUNT(*) as count\n",
    "    FROM tweets\n",
    "    GROUP BY user\n",
    "    ORDER BY count DESC\"\"\"\n",
    "\n",
    "# running the SQL query and showing result\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453d8738",
   "metadata": {},
   "source": [
    "### DATES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "227deb9e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 36:======================================>                   (2 + 1) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-------------------+--------+---------------+--------------------+\n",
      "|index|        id|               date|    flag|           user|                text|\n",
      "+-----+----------+-------------------+--------+---------------+--------------------+\n",
      "|    0|1467810369|2009-04-07 06:19:45|NO_QUERY|_TheSpecialOne_|@switchfoot http:...|\n",
      "|    1|1467810672|2009-04-07 06:19:49|NO_QUERY|  scotthamilton|is upset that he ...|\n",
      "|    2|1467810917|2009-04-07 06:19:53|NO_QUERY|       mattycus|@Kenichan I dived...|\n",
      "|    4|1467811193|2009-04-07 06:19:57|NO_QUERY|         Karoli|@nationwideclass ...|\n",
      "|    3|1467811184|2009-04-07 06:19:57|NO_QUERY|        ElleCTF|my whole body fee...|\n",
      "|    5|1467811372|2009-04-07 06:20:00|NO_QUERY|       joy_wolf|@Kwesidei not the...|\n",
      "|    6|1467811592|2009-04-07 06:20:03|NO_QUERY|        mybirch|         Need a hug |\n",
      "|    7|1467811594|2009-04-07 06:20:03|NO_QUERY|           coZZ|@LOLTrish hey  lo...|\n",
      "|    8|1467811795|2009-04-07 06:20:05|NO_QUERY|2Hood4Hollywood|@Tatiana_K nope t...|\n",
      "|    9|1467812025|2009-04-07 06:20:09|NO_QUERY|        mimismo|@twittera que me ...|\n",
      "|   10|1467812416|2009-04-07 06:20:16|NO_QUERY| erinx3leannexo|spring break in p...|\n",
      "|   11|1467812579|2009-04-07 06:20:17|NO_QUERY|   pardonlauren|I just re-pierced...|\n",
      "|   12|1467812723|2009-04-07 06:20:19|NO_QUERY|           TLeC|@caregiving I cou...|\n",
      "|   13|1467812771|2009-04-07 06:20:19|NO_QUERY|robrobbierobert|@octolinz16 It it...|\n",
      "|   14|1467812784|2009-04-07 06:20:20|NO_QUERY|    bayofwolves|@smarrison i woul...|\n",
      "|   15|1467812799|2009-04-07 06:20:20|NO_QUERY|     HairByJess|@iamjazzyfizzle I...|\n",
      "|   16|1467812964|2009-04-07 06:20:22|NO_QUERY| lovesongwriter|Hollis' death sce...|\n",
      "|   17|1467813137|2009-04-07 06:20:25|NO_QUERY|       armotley|about to file taxes |\n",
      "|   18|1467813579|2009-04-07 06:20:31|NO_QUERY|     starkissed|@LettyA ahh ive a...|\n",
      "|   19|1467813782|2009-04-07 06:20:34|NO_QUERY|      gi_gi_bee|@FakerPattyPattz ...|\n",
      "+-----+----------+-------------------+--------+---------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Ordering rows by date\n",
    "tweetsDf= tweetsDf.orderBy(\"date\")\n",
    "tweetsDf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "62e0857c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking if the df is ordered by id\n",
    "# aggregation on the df and calculation of the min and max values of parameter \"id\"\n",
    "#checking if min_id < max_id, returning a df with a single Boolean value\n",
    "# collect executes the transformations and select access row 0 column 0 from resulting df\n",
    "tweetsDf.agg(F.min(\"id\").alias(\"min_id\"), F.max(\"id\").alias(\"max_id\")) \\\n",
    "                    .select(F.col(\"min_id\") < F.col(\"max_id\")) \\\n",
    "                    .collect()[0][0]\n",
    "\n",
    "# True confirms the df is ordered by id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "34a6ea5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# is the df ordered by index? Same code as above\n",
    "tweetsDf.agg(F.min(\"index\").alias(\"min_index\"), F.max(\"index\").alias(\"max_index\")) \\\n",
    "                    .select(F.col(\"min_index\") < F.col(\"max_index\")) \\\n",
    "                    .collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cacfbeff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 51:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum date:  2009-04-07 06:19:45 \n",
      "maximum date:  2009-06-25 18:28:31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "min_date, max_date = tweetsDf.select(min(\"date\"), max(\"date\")).first()\n",
    "print('minimum date: ',min_date,'\\nmaximum date: ',max_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c870ed86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7b759419",
   "metadata": {},
   "source": [
    "## Text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b55e43",
   "metadata": {},
   "source": [
    "#### Tweets in English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18f2198",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langdetect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "800799fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing library for language detection\n",
    "from langdetect import detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b4cc0d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_language(tweet):\n",
    "    try:\n",
    "        return detect(tweet)\n",
    "    except:\n",
    "        return 'unknown'  # Return 'unknown' in case of an error with langdetect\n",
    "\n",
    "# Register the UDF\n",
    "detect_language_udf = udf(detect_language)\n",
    "\n",
    "# Add a new column 'language' to the DataFrame with the detected language\n",
    "tweetsDf = tweetsDf.withColumn('language', detect_language_udf(col('text')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "52064502",
   "metadata": {},
   "outputs": [],
   "source": [
    "nonEnglishTweetsDf = tweetsDf.filter(col('language') != 'en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373bbbb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 57:=>  (1 + 1) / 3][Stage 58:>   (0 + 0) / 2][Stage 59:>   (0 + 0) / 2]\r"
     ]
    }
   ],
   "source": [
    "tweetsDf.select(col(\"text\"), col(\"language\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063804a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nonEnglishTweetsDf.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8756740b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out non-English tweets\n",
    "englishTweetsDf = tweetsDf.filter(col('language') == 'en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a545e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the number of tweets in English\n",
    "englishTweetsDf.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918004b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweetsDf.write.parquet('savedTweetsDf.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d3b526",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "579b6a8c",
   "metadata": {},
   "source": [
    "#### more EDA about dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d73d519",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# from pyspark.sql.window import Window\n",
    "\n",
    "# # Create a window specification to define the order by 'date'\n",
    "# windowSpec = Window.orderBy(\"date\")\n",
    "\n",
    "# adding a column that represents the previous 'date' value\n",
    "tweetsDf = tweetsDf.withColumn(\"prev_date\", F.lag(\"date\").over(tweetsDf))\n",
    "\n",
    "# filtering out rows where there is a missing date\n",
    "missing_dates_df = tweetsDf.filter((F.col(\"date\") - F.col(\"prev_date\") > F.expr(\"INTERVAL 1 DAY\")) | F.col(\"prev_date\").isNull())\n",
    "\n",
    "missing_dates_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b4887e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#spark = SparkSession.builder.appName(\"MissingDates\").getOrCreate()\n",
    "\n",
    "#generating df with all dates between min_date and max_date\n",
    "all_dates_df = spark.range((max_date - min_date).days + 1).selectExpr(f\"date_add('{min_date}', CAST(id as int)) as all_dates\")\n",
    "\n",
    "# left anti-join to get the missing dates\n",
    "missing_dates_df = all_dates_df.join(tweetsDf, all_dates_df[\"all_dates\"] == tweetsDf[\"date\"], \"leftanti\")\n",
    "\n",
    "# collecting and print the missing dates\n",
    "missing_dates = missing_dates_df.select(date_format(\"all_dates\", \"EEE MMM dd HH:mm:ss zzz yyyy\").alias(\"missing_dates\")).collect()\n",
    "for row in missing_dates:\n",
    "    print(row[\"missing_dates\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e701834",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweetsDf.agg(F.min(\"date\")).collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a9c277",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweetsDf.agg(F.max(\"date\")).collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705e6147",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query = \"\"\"\n",
    "SELECT *,\n",
    "       UNIX_TIMESTAMP(date) - LAG(UNIX_TIMESTAMP(date), 1, 0) OVER (ORDER BY date) AS gap_seconds\n",
    "FROM tweets\n",
    "ORDER BY gap_seconds DESC\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(sql_query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71de927b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gaps_df = spark.sql(\"\"\"\n",
    "    SELECT DATE_ADD(d1, 1) AS missing_date\n",
    "    FROM (\n",
    "        SELECT CAST(date AS DATE) AS d1, \n",
    "               LEAD(CAST(date AS DATE), 1) OVER (ORDER BY date) AS d2\n",
    "        FROM tweets\n",
    "    ) temp\n",
    "    WHERE DATE_ADD(d1, 1) < d2\n",
    "\"\"\")\n",
    "\n",
    "# Count the number of gaps in days\n",
    "gaps_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c109cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SQL with a CTE to find the rows with missing timestamps in between\n",
    "result_df = spark.sql(\"\"\"\n",
    "    WITH Temp AS (\n",
    "        SELECT *,\n",
    "               DATE_ADD(CAST(date AS DATE), 1) AS next_date,\n",
    "               LEAD(CAST(date AS DATE), 1) OVER (ORDER BY date) AS lead_date\n",
    "        FROM tweets\n",
    "    )\n",
    "    SELECT *\n",
    "    FROM Temp\n",
    "    WHERE next_date < lead_date\n",
    "\"\"\")\n",
    "\n",
    "result_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc4bd54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
